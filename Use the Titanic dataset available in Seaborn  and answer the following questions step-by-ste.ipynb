{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "948f314d-ec97-4a9a-a6b5-937ce392f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fca1c10-6b8e-4db2-b14c-674a0397da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. Data Loading and Exploration\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Load the Titanic dataset using Seaborn\n",
    "titanic = sns.load_dataset('titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b2a498-5861-4778-9f17-48bfb1cd00d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 rows of the dataset:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "5         0       3    male   NaN      0      0   8.4583        Q   Third   \n",
      "6         0       1    male  54.0      0      0  51.8625        S   First   \n",
      "7         0       3    male   2.0      3      1  21.0750        S   Third   \n",
      "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "5    man        True  NaN   Queenstown    no   True  \n",
      "6    man        True    E  Southampton    no   True  \n",
      "7  child       False  NaN  Southampton    no  False  \n",
      "8  woman       False  NaN  Southampton   yes  False  \n",
      "9  child       False  NaN    Cherbourg   yes  False  \n"
     ]
    }
   ],
   "source": [
    "# 2. Display the first 10 rows of the dataset\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "print(titanic.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f85324b-170c-45f4-94d5-b3a76f04f4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape (rows, columns): (891, 15)\n"
     ]
    }
   ],
   "source": [
    "# 3. Find the total number of rows and columns\n",
    "print(\"\\nDataset shape (rows, columns):\", titanic.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01fda651-d174-4e6a-8b11-0227d18e9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 4. Display column names, data types, and non-null counts\n",
    "print(\"\\nDataset information:\")\n",
    "print(titanic.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a952689b-10a3-4c50-85df-fa926214ad40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 5. Identify the number of missing values in each column\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(titanic.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a861c2b-df49-444c-ad78-e20733ef9d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Insights:\n",
      "\n",
      "• The dataset contains information about 891 passengers.\n",
      "• There are 15 columns with mixed data types: numeric, categorical, and boolean.\n",
      "• Missing values are present notably in 'age', 'deck', and 'embark_town'.\n",
      "• The dataset includes survival information and passenger demographics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Insights\n",
    "print(\"\\nInsights:\")\n",
    "print(\"\"\"\n",
    "• The dataset contains information about 891 passengers.\n",
    "• There are 15 columns with mixed data types: numeric, categorical, and boolean.\n",
    "• Missing values are present notably in 'age', 'deck', and 'embark_town'.\n",
    "• The dataset includes survival information and passenger demographics.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3537d1-75a1-41ae-a315-5f2054f9c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns with missing values: ['age', 'embarked', 'deck', 'embark_town']\n"
     ]
    }
   ],
   "source": [
    "# Q2. Handling Missing Values\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. List columns with missing values\n",
    "missing_cols = titanic.columns[titanic.isnull().any()].tolist()\n",
    "print(\"\\nColumns with missing values:\", missing_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "218a9821-dc29-4d7c-81a2-1a1d1ed26dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\first\\AppData\\Local\\Temp\\ipykernel_13176\\3657768101.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['age'].fillna(titanic['age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 2. Handle missing values in specific columns\n",
    "# Fill 'age' with median\n",
    "titanic['age'].fillna(titanic['age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45548d9-88fe-4ccb-a5f4-abca05f65006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\first\\AppData\\Local\\Temp\\ipykernel_13176\\4202355943.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\first\\AppData\\Local\\Temp\\ipykernel_13176\\4202355943.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  titanic['embark_town'].fillna(titanic['embark_town'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Fill 'embarked' and 'embark_town' with mode\n",
    "titanic['embarked'].fillna(titanic['embarked'].mode()[0], inplace=True)\n",
    "titanic['embark_town'].fillna(titanic['embark_town'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019cb0ad-4564-41f7-9cd0-a6a46aff5306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'deck' column (too many missing values)\n",
    "titanic.drop(columns=['deck'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64ad83cd-2367-4b7e-8b73-b3005d88c1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values after handling:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3. Verify that missing values are handled\n",
    "print(\"\\nMissing values after handling:\")\n",
    "print(titanic.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbac41ed-4392-4117-8ce1-1519acaffeed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of duplicate rows: 116\n"
     ]
    }
   ],
   "source": [
    "# Q3. Handling Duplicate Data\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Check for duplicate rows\n",
    "duplicates = titanic.duplicated().sum()\n",
    "print(\"\\nNumber of duplicate rows:\", duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e185400-7908-4a9a-b684-a746f68c1e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dataset shape after removing duplicates: (775, 14)\n"
     ]
    }
   ],
   "source": [
    "# 2. Remove duplicates if any\n",
    "if duplicates > 0:\n",
    "    titanic.drop_duplicates(inplace=True)\n",
    "print(\"New dataset shape after removing duplicates:\", titanic.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2cca19b3-6a36-453f-b408-df61fb58b28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Categorical columns: ['sex', 'embarked', 'class', 'who', 'adult_male', 'embark_town', 'alive', 'alone']\n"
     ]
    }
   ],
   "source": [
    "# Q4. Encoding Categorical Variables\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Identify categorical columns\n",
    "categorical_cols = titanic.select_dtypes(include=['object', 'category', 'bool']).columns\n",
    "print(\"\\nCategorical columns:\", list(categorical_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "862702d7-6a8d-4b8a-aedf-4022ed573429",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Convert 'sex' column to numeric form\n",
    "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ced6a42-7e27-431a-9020-26956f177e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Apply one-hot encoding on selected categorical columns\n",
    "titanic = pd.get_dummies(titanic, columns=['embarked', 'class', 'who', 'alone', 'adult_male'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed06b45c-c5a6-44bc-9e7a-4c00457efc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Columns after encoding:\n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embark_town', 'alive', 'embarked_Q', 'embarked_S', 'class_Second',\n",
      "       'class_Third', 'who_man', 'who_woman', 'alone_True', 'adult_male_True'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumns after encoding:\")\n",
    "print(titanic.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a26b120-aed6-4f87-baba-f3dd7b7cca3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding categorical variables is necessary because:\n",
      "• Machine learning models require numerical input.\n",
      "• It helps the model understand categorical distinctions.\n",
      "• Prevents bias caused by arbitrary numerical labeling.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Explanation\n",
    "print(\"\"\"\n",
    "Encoding categorical variables is necessary because:\n",
    "• Machine learning models require numerical input.\n",
    "• It helps the model understand categorical distinctions.\n",
    "• Prevents bias caused by arbitrary numerical labeling.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0634fef-eb22-4f19-acc9-d415931242bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature scaling ensures all numeric features are on a similar scale.\n",
      "It improves convergence in gradient-based algorithms and avoids dominance by features with large ranges.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q5. Feature Scaling\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Explanation\n",
    "print(\"\"\"\n",
    "Feature scaling ensures all numeric features are on a similar scale.\n",
    "It improves convergence in gradient-based algorithms and avoids dominance by features with large ranges.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c263a05e-b9a4-4545-882e-95c8923b7474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Apply StandardScaler to 'age' and 'fare'\n",
    "scaler = StandardScaler()\n",
    "titanic[['age_scaled', 'fare_scaled']] = scaler.fit_transform(titanic[['age', 'fare']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d59cb06-1e25-439f-9df8-f2f50fb1085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original vs Scaled comparison (first 5 rows):\n",
      "    age  age_scaled     fare  fare_scaled\n",
      "0  22.0   -0.551060   7.2500    -0.527515\n",
      "1  38.0    0.611945  71.2833     0.695086\n",
      "2  26.0   -0.260308   7.9250    -0.514627\n",
      "3  35.0    0.393881  53.1000     0.347909\n",
      "4  35.0    0.393881   8.0500    -0.512240\n"
     ]
    }
   ],
   "source": [
    "# 3. Compare scaled vs. original values\n",
    "print(\"\\nOriginal vs Scaled comparison (first 5 rows):\")\n",
    "print(titanic[['age', 'age_scaled', 'fare', 'fare_scaled']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f61b5d73-4444-4c68-8b80-3a45774d3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. Feature Engineering\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Create family_size = sibsp + parch + 1\n",
    "titanic['family_size'] = titanic['sibsp'] + titanic['parch'] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6704bb16-b939-4d9e-bc94-192ef048e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create is_child column (True if age < 18)\n",
    "titanic['is_child'] = titanic['age'] < 18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1037f572-0f7d-400f-8d16-e50c75741df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New features help prediction:\n",
      "• family_size: Larger families might affect survival chances.\n",
      "• is_child: Children may have been given evacuation priority.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Explanation\n",
    "print(\"\"\"\n",
    "New features help prediction:\n",
    "• family_size: Larger families might affect survival chances.\n",
    "• is_child: Children may have been given evacuation priority.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb59c36e-0366-4de6-8370-ed230c0339ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Dropping Irrelevant Columns\n",
    "# ----------------------------------------------\n",
    "\n",
    "# 1. Identify and drop irrelevant columns\n",
    "irrelevant_cols = ['alive', 'embark_town']\n",
    "titanic.drop(columns=irrelevant_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23f1b858-2d70-4be2-870a-643e79f650e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dropped columns:\n",
      "• 'alive': Duplicate information (same as 'survived').\n",
      "• 'embark_town': Redundant since 'embarked' already encodes this info.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Justification\n",
    "print(\"\"\"\n",
    "Dropped columns:\n",
    "• 'alive': Duplicate information (same as 'survived').\n",
    "• 'embark_town': Redundant since 'embarked' already encodes this info.\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e14cbc8-43ba-45f6-96c9-655f9b2da413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned dataset (first 5 rows):\n",
      "   survived  pclass  sex   age  sibsp  parch     fare  embarked_Q  embarked_S  \\\n",
      "0         0       3    0  22.0      1      0   7.2500       False        True   \n",
      "1         1       1    1  38.0      1      0  71.2833       False       False   \n",
      "2         1       3    1  26.0      0      0   7.9250       False        True   \n",
      "3         1       1    1  35.0      1      0  53.1000       False        True   \n",
      "4         0       3    0  35.0      0      0   8.0500       False        True   \n",
      "\n",
      "   class_Second  class_Third  who_man  who_woman  alone_True  adult_male_True  \\\n",
      "0         False         True     True      False       False             True   \n",
      "1         False        False    False       True       False            False   \n",
      "2         False         True    False       True        True            False   \n",
      "3         False        False    False       True       False            False   \n",
      "4         False         True     True      False        True             True   \n",
      "\n",
      "   age_scaled  fare_scaled  family_size  is_child  \n",
      "0   -0.551060    -0.527515            2     False  \n",
      "1    0.611945     0.695086            2     False  \n",
      "2   -0.260308    -0.514627            1     False  \n",
      "3    0.393881     0.347909            2     False  \n",
      "4    0.393881    -0.512240            1     False  \n",
      "\n",
      "Missing values check after cleaning:\n",
      "survived           0\n",
      "pclass             0\n",
      "sex                0\n",
      "age                0\n",
      "sibsp              0\n",
      "parch              0\n",
      "fare               0\n",
      "embarked_Q         0\n",
      "embarked_S         0\n",
      "class_Second       0\n",
      "class_Third        0\n",
      "who_man            0\n",
      "who_woman          0\n",
      "alone_True         0\n",
      "adult_male_True    0\n",
      "age_scaled         0\n",
      "fare_scaled        0\n",
      "family_size        0\n",
      "is_child           0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows after cleaning: 0\n",
      "\n",
      "Data types after cleaning:\n",
      "survived             int64\n",
      "pclass               int64\n",
      "sex                  int64\n",
      "age                float64\n",
      "sibsp                int64\n",
      "parch                int64\n",
      "fare               float64\n",
      "embarked_Q            bool\n",
      "embarked_S            bool\n",
      "class_Second          bool\n",
      "class_Third           bool\n",
      "who_man               bool\n",
      "who_woman             bool\n",
      "alone_True            bool\n",
      "adult_male_True       bool\n",
      "age_scaled         float64\n",
      "fare_scaled        float64\n",
      "family_size          int64\n",
      "is_child              bool\n",
      "dtype: object\n",
      "\n",
      "Summary of Cleaning Steps:\n",
      "• Loaded dataset and explored structure.\n",
      "• Handled missing values using median/mode.\n",
      "• Removed duplicates.\n",
      "• Encoded categorical columns.\n",
      "• Scaled numeric columns.\n",
      "• Engineered new features.\n",
      "• Dropped irrelevant columns.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q8. Final Data Verification\n",
    "# ----------------------------------------------\n",
    "\n",
    "print(\"\\nCleaned dataset (first 5 rows):\")\n",
    "print(titanic.head())\n",
    "\n",
    "print(\"\\nMissing values check after cleaning:\")\n",
    "print(titanic.isnull().sum())\n",
    "\n",
    "print(\"\\nDuplicate rows after cleaning:\", titanic.duplicated().sum())\n",
    "\n",
    "print(\"\\nData types after cleaning:\")\n",
    "print(titanic.dtypes)\n",
    "\n",
    "print(\"\"\"\n",
    "Summary of Cleaning Steps:\n",
    "• Loaded dataset and explored structure.\n",
    "• Handled missing values using median/mode.\n",
    "• Removed duplicates.\n",
    "• Encoded categorical columns.\n",
    "• Scaled numeric columns.\n",
    "• Engineered new features.\n",
    "• Dropped irrelevant columns.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8ad5fcf-5fdd-4724-b7b4-af5da2837298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reflection:\n",
      "1. Data cleaning is critical because it removes noise, handles missing values, and ensures consistent data formats — improving model accuracy.\n",
      "2. Handling missing values had the greatest impact, as missing 'age' and 'deck' could have misled analyses.\n",
      "3. For large real-world datasets, automation, distributed processing (e.g., Spark), and scalable imputation techniques would be used.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------\n",
    "# Q9. Reflection / Discussion\n",
    "# ----------------------------------------------\n",
    "\n",
    "print(\"\"\"\n",
    "Reflection:\n",
    "1. Data cleaning is critical because it removes noise, handles missing values, and ensures consistent data formats — improving model accuracy.\n",
    "2. Handling missing values had the greatest impact, as missing 'age' and 'deck' could have misled analyses.\n",
    "3. For large real-world datasets, automation, distributed processing (e.g., Spark), and scalable imputation techniques would be used.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76f369c-48d9-4a04-8022-f820bb5120b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
